{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, row_number\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from itertools import chain\n",
    "from pyspark.sql.types import StringType, MapType, IntegerType\n",
    "mapCol = MapType(IntegerType(),StringType(),False)\n",
    "\n",
    "spark=SparkSession.builder.appName(\"dataETL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberData=spark.read.parquet(\"C:/Users/hgarg/OneDrive/Desktop/PySpark/yellow_tripdata_2022-01.parquet\")\n",
    "\n",
    "#Adding a new Column as index\n",
    "uberRideData = uberData.withColumn(\"UberId\", row_number().over(Window.partitionBy(\"VendorId\", \"tpep_pickup_datetime\").orderBy(\"VendorId\",\"tpep_pickup_datetime\")))\n",
    "uberRawDataDf = uberRideData.select(\"UberId\", \"VendorId\")\n",
    "uberRideData.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PickUp and DropOff time details\n",
    "weekDays = {\n",
    "    1: \"Monday\",\n",
    "    2: \"Tuesday\",\n",
    "    3: \"Wednesday\",\n",
    "    4: \"Thursday\",\n",
    "    5: \"Friday\",\n",
    "    6: \"Saturday\",\n",
    "    7: \"Sunday\"\n",
    "}\n",
    "months = {\n",
    "    1: \"January\",\n",
    "    2: \"February\",\n",
    "    3: \"March\",\n",
    "    4: \"April\",\n",
    "    5: \"May\",\n",
    "    6: \"June\",\n",
    "    7: \"July\",\n",
    "    8: \"August\",\n",
    "    9: \"September\",\n",
    "    10: \"October\",\n",
    "    11: \"November\",\n",
    "    12: \"December\"\n",
    "}\n",
    "mapWeek = F.create_map(*[F.lit(x) for x in chain(*weekDays.items())])\n",
    "mapMonth = F.create_map(*[F.lit(x) for x in chain(*months.items())])\n",
    "pickDropDetails = uberRideData.select(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\").distinct()\n",
    "pickDropDf = pickDropDetails.withColumn(\"UberPickUpId\", monotonically_increasing_id())\\\n",
    "    .withColumn(\"pickUpHour\", F.hour(col(\"tpep_pickup_datetime\"))).withColumn(\"pickUpMin\", F.minute(col(\"tpep_pickup_datetime\")))\\\n",
    "    .withColumn(\"pickUpSec\", F.second(col(\"tpep_pickup_datetime\"))).withColumn(\"pickUpDay\", mapWeek[F.dayofweek(col(\"tpep_pickup_datetime\"))])\\\n",
    "    .withColumn(\"pickUpMonth\", mapMonth[F.month(col(\"tpep_pickup_datetime\"))]).withColumn(\"pickUpYear\", F.year(col(\"tpep_pickup_datetime\")))\\\n",
    "    .withColumn(\"dropOffHour\", F.hour(col(\"tpep_dropoff_datetime\"))).withColumn(\"dropOffMin\", F.minute(col(\"tpep_dropoff_datetime\")))\\\n",
    "    .withColumn(\"dropOffSec\", F.second(col(\"tpep_dropoff_datetime\"))).withColumn(\"dropOffDay\", mapWeek[F.dayofweek(col(\"tpep_dropoff_datetime\"))])\\\n",
    "    .withColumn(\"dropOffMonth\", mapMonth[F.month(col(\"tpep_dropoff_datetime\"))]).withColumn(\"dropOffYear\", F.year(col(\"tpep_dropoff_datetime\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passenger Details\n",
    "passengerDetails = uberRideData.select(\"passenger_count\").distinct().filter(col(\"passenger_count\").isNotNull())\n",
    "passengerDetailsDF = passengerDetails.withColumn(\"UberPassengerId\", monotonically_increasing_id())\\\n",
    "    .withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trip Details\n",
    "tripDetails = uberRideData.select(\"trip_distance\").distinct().filter(col(\"trip_distance\").isNotNull())\n",
    "tripDetailsDF = tripDetails.withColumn(\"UberTripId\", monotonically_increasing_id())\\\n",
    "    .withColumnRenamed(\"trip_distance\", \"TripDistance(km)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Rate Card Table\n",
    "from itertools import chain\n",
    "rateDic = {\n",
    "    1: \"Standard Rate\",\n",
    "    2: \"JFK\",\n",
    "    3: \"Newark\",\n",
    "    4: \"Nassau or WestChester\",\n",
    "    5: \"Negotiated Fair\",\n",
    "    6: \"Group Ride\",\n",
    "    99: \"Premium\"}\n",
    "\n",
    "rateMap = F.create_map(*[F.lit(x) for x in chain(*rateDic.items())])\n",
    "\n",
    "tripRateDetails = uberRideData.select(\"RateCodeId\").distinct().filter(col(\"RateCodeId\").isNotNull())\n",
    "tripRateDetailsDf = tripRateDetails.withColumn(\"UberFairId\", monotonically_increasing_id())\\\n",
    "    .withColumn(\"RateCodeId\", col(\"RateCodeId\").cast(\"integer\"))\n",
    "\n",
    "fairCardDetails = tripRateDetailsDf.withColumn(\"FairId\", rateMap[col(\"RateCodeId\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-----------+\n",
      "|UberPaymentId|paymentModeId|paymentMode|\n",
      "+-------------+-------------+-----------+\n",
      "|            0|            0|Credit Card|\n",
      "|            1|            1|       Cash|\n",
      "|            2|            3|    Dispute|\n",
      "|            3|            2|  No Charge|\n",
      "|            4|            4|    Unknown|\n",
      "|            5|            5|Voided Trip|\n",
      "+-------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Payment Mode Storage\n",
    "from itertools import chain\n",
    "paymentMode = {\n",
    "    0: \"Credit Card\",\n",
    "    1: \"Cash\",\n",
    "    2: \"No Charge\",\n",
    "    3: \"Dispute\",\n",
    "    4: \"Unknown\",\n",
    "    5: \"Voided Trip\"}\n",
    "\n",
    "paymentModeMap = F.create_map(*[F.lit(x) for x in chain(*paymentMode.items())])\n",
    "\n",
    "paymentModeDetails = uberRideData.select(\"payment_Type\").distinct().filter(col(\"payment_Type\").isNotNull())\n",
    "paymentModeDetailsDf = paymentModeDetails.withColumn(\"UberPaymentId\", monotonically_increasing_id())\\\n",
    "    .withColumn(\"paymentModeId\", col(\"payment_Type\").cast(\"integer\"))\n",
    "\n",
    "paymentModeDetailsFinalDf = paymentModeDetailsDf.withColumn(\"paymentMode\", paymentModeMap[col(\"payment_Type\")])\\\n",
    "    .select(\"UberPaymentId\", \"paymentModeId\", \"paymentMode\")\n",
    "\n",
    "paymentModeDetailsFinalDf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Location Table\n",
    "locationDetails = uberRideData.selectExpr(\"PULocationID as PickUpLocationId\", \"DOLocationID as DropOffLocationId\")\\\n",
    "    .distinct().filter(col(\"PULocationID\").isNotNull()).distinct().filter(col(\"DOLocationID\").isNotNull())\n",
    "locationDetailsDf = locationDetails.withColumn( \"UberLocationId\", monotonically_increasing_id())\n",
    "locationDetailsDf.select(\"PickUpLocationId\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---------------+----------+----------+-------------+--------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|UberId|UberPickUpId|UberPassengerId|UberTripId|UberFairId|UberPaymentId|UberLocationId|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+------+------------+---------------+----------+----------+-------------+--------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|     1|           1|              1|         1|         1|            1|             1|        8.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        11.8|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       13.5|  3.0|    0.5|      3.46|         0.0|                  0.3|       20.76|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        4.5|  0.5|    0.5|       4.0|         0.0|                  0.3|         9.8|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        5.5|  3.0|    0.5|       2.3|         0.0|                  0.3|        11.6|\n",
      "|     1|           1|              1|         1|         1|            1|             1|      113.5| 1.75|    0.5|      24.5|        6.55|                  0.3|       147.1|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        9.0|  3.0|    0.5|      5.75|         0.0|                  0.3|       18.55|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       10.5|  3.0|    0.5|       1.0|         0.0|                  0.3|        15.3|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        5.0|  3.0|    0.5|       1.0|         0.0|                  0.3|         9.8|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        9.0|  3.0|    0.5|      1.92|         0.0|                  0.3|       14.72|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        9.5|  3.0|    0.5|       1.0|         0.0|                  0.3|        14.3|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       13.5|  3.0|    0.5|      3.45|         0.0|                  0.3|       20.75|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       10.0|  3.0|    0.5|       2.0|         0.0|                  0.3|        15.8|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       67.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        70.8|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        4.0|  3.0|    0.5|       2.3|         0.0|                  0.3|        10.1|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       15.0|  0.0|    0.0|       0.0|         0.0|                  0.3|        15.3|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       80.0|  0.0|    0.0|       5.0|         0.0|                  0.3|        85.3|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        6.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        10.3|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       27.5|  3.0|    0.5|      6.25|         0.0|                  0.3|       37.55|\n",
      "|     1|           1|              1|         1|         1|            1|             1|       14.5|  3.0|    0.5|      3.65|         0.0|                  0.3|       21.95|\n",
      "|     1|           1|              1|         1|         1|            1|             1|        7.0|  3.0|    0.5|       1.0|         0.0|                  0.3|        11.8|\n",
      "+------+------------+---------------+----------+----------+-------------+--------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Joining all the dataframes\n",
    "finalFactRawData = uberRideData.join(pickDropDf, uberRideData[\"UberId\"] == pickDropDf[\"UberPickUpId\"], \"left\")\\\n",
    "    .join(passengerDetailsDF, uberRideData[\"UberId\"] == passengerDetailsDF[\"UberPassengerId\"], \"left\")\\\n",
    "    .join(tripDetailsDF, uberRideData[\"UberId\"] == tripDetailsDF[\"UberTripId\"], \"left\")\\\n",
    "    .join(fairCardDetails, uberRideData[\"UberId\"] == fairCardDetails[\"UberFairId\"], \"left\")\\\n",
    "    .join(paymentModeDetailsFinalDf, uberRideData[\"UberId\"] == paymentModeDetailsFinalDf[\"UberPaymentId\"], \"left\")\\\n",
    "    .join(locationDetailsDf, uberRideData[\"UberId\"] == locationDetailsDf[\"UberLocationId\"], \"left\")\n",
    "\n",
    "finalData = finalFactRawData.select(\"UberId\", \"UberPickUpId\", \"UberPassengerId\", \"UberTripId\", \"UberFairId\", \"UberPaymentId\", \"UberLocationId\", \"fare_amount\",\n",
    "                     \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\")\n",
    "\n",
    "finalData.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
